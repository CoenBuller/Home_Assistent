# ------ 10-04-2025 -------
I now have the code that can extract mfcc's from a sound file and cut it into multiple 
smaller files. This code can also augment to data to 'corrupt' it. This means I have collected
all the needed data and only need to adjust it so that the larger files are seperated into
multiple smaller files. Adjecent to that I also need to label all the sound files. 
To-Do list:
 - Cut larger soundfiles into smaller ones. 
 - Label the data correctly 
 - Learn how to work with the pytorch dataloader
 - Check if for the GRU model if it can continuously evaluate sounddata. If it is given in
    chunks of 1 seconds, can it remember the previouse chuncks when given a new one. 
 - Train and test the wake word detector

# ------ 14-04-2025 -------
I have now cutted the background audio into smaller audio files. I will now work with this but if it doesn't work, check if the GRU will identify correctly if the wake word is seperated over different audio segements. 

# ------ 16-05-2025 -------
Make shure that all the audio files are only two seconds long, train the model again and change the test_wake_word_detector.py file just so it constantly checks audio pieces of 2 seconds.

# ------ 17-05-2025 -------
Check how RNNs exactly work, especially if you take one mfcc frame and feed that to the RNN, will it then update its internal state. In other words: find out if you can feed the RNN one MFCC segment at a time or do you need to feed it 2s long segments each time. The latter would significantly increase the computation time and would suck for the raspberry. 

Also chech the masking of the MFCC spectogram during training. It now sets a time series and a certain frequency to zero but perhaps it is better if it is set to the minimum value of that spectogram. Look into that