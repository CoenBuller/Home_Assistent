# ------ 10-04-2025 -------
I now have the code that can extract mfcc's from a sound file and cut it into multiple 
smaller files. This code can also augment to data to 'corrupt' it. This means I have collected
all the needed data and only need to adjust it so that the larger files are seperated into
multiple smaller files. Adjecent to that I also need to label all the sound files. 
To-Do list:
 - Cut larger soundfiles into smaller ones. 
 - Label the data correctly 
 - Learn how to work with the pytorch dataloader
 - Check if for the GRU model if it can continuously evaluate sounddata. If it is given in
    chunks of 1 seconds, can it remember the previouse chuncks when given a new one. 
 - Train and test the wake word detector

# ------ 14-04-2025 -------
I have now cutted the background audio into smaller audio files. I will now work with this but if it doesn't work, check if the GRU will identify correctly if the wake word is seperated over different audio segements. 

# ------ 16-05-2025 -------
Make shure that all the audio files are only two seconds long, train the model again and change the test_wake_word_detector.py file just so it constantly checks audio pieces of 2 seconds.

# ------ 17-05-2025 -------
Check how RNNs exactly work, especially if you take one mfcc frame and feed that to the RNN, will it then update its internal state. In other words: find out if you can feed the RNN one MFCC segment at a time or do you need to feed it 2s long segments each time. The latter would significantly increase the computation time and would suck for the raspberry. 

Also chech the masking of the MFCC spectogram during training. It now sets a time series and a certain frequency to zero but perhaps it is better if it is set to the minimum value of that spectogram. Look into that

# ------ 18-05-2025 -------
The RNN does activate on the 'Jarvis' input but also on silence. To increase accuracy I will make it look at one second windows, record new samples of me saying jarvis within a one second timeframe, and train the model again. This will also reduce computation cost for the model. Also increase the stepsize in which program 'convolutes' over the recorded audio. This hsould also decrease computation cost and create a more accurate output. Next to that also implement a sleep method so the model doesn't detect the wakeword multiple times in the same audio.

It appears that it does recognize Jarvis but other words like nice and stuff are also detected. This means that I have to record audio files that contian the word nice and similar sounding words. Furthermore it might be better if we train applying softmax at the end, then we can train the model on the probabilities. Also change the criteria on the accuracy form the maximum to the maximum value and the probability must be higher than a certain threshold. Also add validation loss to the 'accuracy' function. 

To Do:
- Record audio files containing words similar to jarvis and word that sound similar to nice. 
- Apply softmax at the end of fully connected line. 
- Change accuracy in such a way that the threshold must be above a certain value (e.g. 99% certain)
- Add loss value to the 'accuracy' function

# ------ 19-05-2025 ------
I've applied a softmax to the outputs of the model, changed the accuracy threshold to higher than 99% for the correct label and lower then 1% for the incorrect label. This didn't solve the previous problem, and made it appear the model is highly focussing on the 'vis' part of Jarvis. The reason for this suspicion is due to the fact that the model thinks I am saying Jarvis when in reality I am saying 'is' or 'nice' or 'vis'. At the same time the model doesn't get triggered when I say 'Jar', which confirms my suspicion. So adding words that look like 'is', 'nice', or 'vis' in the non wakeword audio map might improve this. Also think about how to go over the background noice and common voice audio files. A better approach would be to split up the background and common voice audio in a convolutional manner. The same way we process the live audio input when the model tries to determine wether I am saying 'Jarvis' or not. 

To Do:
- Record audio files containing words similar to jarvis and word that sound similar to 'nice', 'is' and 'vis'.
- Break the longer non wakeword audio files up in a convolutional manner. The same way we process the live audio for detecting the wakeword.